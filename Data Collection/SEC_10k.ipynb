{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e778b150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sec_edgar_downloader\n",
      "  Downloading sec_edgar_downloader-5.0.3-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from sec_edgar_downloader) (2.32.3)\n",
      "Collecting pyrate-limiter>=3.6.0 (from sec_edgar_downloader)\n",
      "  Downloading pyrate_limiter-3.9.0-py3-none-any.whl.metadata (28 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->sec_edgar_downloader) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->sec_edgar_downloader) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->sec_edgar_downloader) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->sec_edgar_downloader) (2024.12.14)\n",
      "Downloading sec_edgar_downloader-5.0.3-py3-none-any.whl (14 kB)\n",
      "Downloading pyrate_limiter-3.9.0-py3-none-any.whl (33 kB)\n",
      "Installing collected packages: pyrate-limiter, sec_edgar_downloader\n",
      "Successfully installed pyrate-limiter-3.9.0 sec_edgar_downloader-5.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sec_edgar_downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a096c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Could not locate any downloaded HTML filing.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 52\u001b[0m\n\u001b[1;32m     48\u001b[0m     item_1a_text \u001b[38;5;241m=\u001b[39m extract_item_1a(html_path)\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28mprint\u001b[39m(item_1a_text[:\u001b[38;5;241m1000\u001b[39m])\n\u001b[0;32m---> 52\u001b[0m item_1a_text \u001b[38;5;241m=\u001b[39m \u001b[43mextract_item_1a\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhtml_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(item_1a_text[:\u001b[38;5;241m1000\u001b[39m])\n",
      "Cell \u001b[0;32mIn[6], line 28\u001b[0m, in \u001b[0;36mextract_item_1a\u001b[0;34m(html_path)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_item_1a\u001b[39m(html_path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhtml_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     29\u001b[0m         soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(f, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m         text \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mget_text(separator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "from sec_edgar_downloader import Downloader\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "\n",
    "def download_latest_filing(ticker: str = \"NVDA\", form_type: str = \"10-Q\") -> str:\n",
    "    dl = Downloader(\"dvschenone@ucsd.edu\", \"sec_data\")\n",
    "    dl.get(form_type, ticker)\n",
    "    return get_latest_filing_file(ticker, form_type)\n",
    "\n",
    "\n",
    "def get_latest_filing_file(ticker: str, form_type: str) -> str:\n",
    "    filings_path = os.path.join(\"sec_data\", \"sec-edgar-filings\", ticker, form_type)\n",
    "    latest_file = None\n",
    "    latest_mtime = 0\n",
    "\n",
    "    for root, _, files in os.walk(filings_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".html\") or file.endswith(\".txt\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                mtime = os.path.getmtime(file_path)\n",
    "                if mtime > latest_mtime:\n",
    "                    latest_file = file_path\n",
    "                    latest_mtime = mtime\n",
    "    return latest_file\n",
    "\n",
    "\n",
    "def extract_item_1a(file_path: str) -> str:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # If HTML-like, use BeautifulSoup\n",
    "    if \"<html\" in content.lower():\n",
    "        soup = BeautifulSoup(content, \"html.parser\")\n",
    "        text = soup.get_text(separator=\"\\n\")\n",
    "    else:\n",
    "        text = content\n",
    "\n",
    "    # Normalize newlines and search\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    pattern = r'(?i)(item\\s+1A\\.?\\s*[-–:]?\\s*Risk\\s+Factors)(.*?)(item\\s+1B\\.?|item\\s+2\\.)'\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "\n",
    "    if match:\n",
    "        return match.group(2).strip()\n",
    "    else:\n",
    "        return \"Item 1A section not found.\"\n",
    "\n",
    "\n",
    "# Example\n",
    "html_path = download_latest_filing(\"NVDA\", \"10-Q\")\n",
    "\n",
    "if html_path is None:\n",
    "    print(\"❌ Could not locate any downloaded filing.\")\n",
    "else:\n",
    "    item_1a_text = extract_item_1a(html_path)\n",
    "    print(item_1a_text[:1000])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
